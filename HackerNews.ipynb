{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Guided Project: Exploring Hacker News Posts\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the guided project on exploring Hacker News posts! In this project, we'll analyze a dataset of submissions to the popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to Reddit. It's extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "The main goals of this project are to:\n",
    "\n",
    "- Work with strings, object-oriented programming, and dates and times.\n",
    "- Analyze the Hacker News dataset to answer the following questions:\n",
    "  - Do Ask HN or Show HN posts receive more comments on average?\n",
    "  - Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "This project will give you hands-on experience with real-world examples, helping you to not only complete it but also to understand the underlying concepts. Feel free to refer to additional lessons if needed, especially if you're new to working with Jupyter Notebook.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset we'll be working with has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post.\n",
    "- `title`: The title of the post.\n",
    "- `url`: The URL that the post links to, if it has a URL.\n",
    "- `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes.\n",
    "- `num_comments`: The number of comments on the post.\n",
    "- `author`: The username of the person who submitted the post.\n",
    "- `created_at`: The date and time of the post's submission.\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "We're specifically interested in posts with titles that begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question, while Show HN posts are used to show the community a project, product, or something interesting.\n",
    "\n",
    "In this project, we'll compare these two types of posts to determine the following:\n",
    "\n",
    "1. Do Ask HN or Show HN posts receive more comments on average?\n",
    "2. Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Let's get started by importing the necessary libraries and reading the dataset into a list of lists.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8bbee537cc490a"
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n",
      "--------------\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "import  csv\n",
    "\n",
    "csv_file_path = 'hacker_news.csv'\n",
    "\n",
    "with open(csv_file_path,'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    headers = next(csv_reader)\n",
    "    \n",
    "    hn= list(csv_reader)\n",
    "\n",
    "print(hn[:5])\n",
    "print(\"--------------\")\n",
    "print(headers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.652831873Z",
     "start_time": "2024-04-24T00:17:14.595901480Z"
    }
   },
   "id": "1eb3e179f7f94c30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "To find the posts that begin with either Ask HN or Show HN, we'll use the string method startswith. Given a string object, say, string1, we can check if starts with, say, dq by inspecting the output of the object string1.startswith('dq'). If string1 starts with dq, it will return True; otherwise, it will return False."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aa7bc7e5c640c8c"
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.703132023Z",
     "start_time": "2024-04-24T00:17:14.677652959Z"
    }
   },
   "id": "d8b283de92d83e3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's explore the first row of each type of posts:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20f96af15254ae8b"
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n",
      "-----------------------------\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n",
      "-----------------------------\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:5])\n",
    "print(\"-----------------------------\")\n",
    "print(show_posts[:5])\n",
    "print(\"-----------------------------\")\n",
    "print(other_posts[:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.703407864Z",
     "start_time": "2024-04-24T00:17:14.677776285Z"
    }
   },
   "id": "c7c3fdc9d64d689d"
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = row[4]\n",
    "    total_ask_comments += int(num_comments)\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = row[4]\n",
    "    total_show_comments += int(num_comments)\n",
    "\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.703501471Z",
     "start_time": "2024-04-24T00:17:14.677816814Z"
    }
   },
   "id": "1096e565ab6bb329"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see there are more comments in ask posts in average "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da32d0d498ed0ef1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "Calculate the number of ask posts created in each hour of the day, along with the number of comments received.\n",
    "Calculate the average number of comments ask posts receive by hour created."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a68852859e2902a4"
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    listData = [created_at,num_comments]\n",
    "    result_list.append(listData)\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    data_object = dt.datetime.strptime(row[0],'%m/%d/%Y %H:%M')\n",
    "    hour = dt.datetime.strftime(data_object,\"%H\")\n",
    "    comments = row[1]\n",
    "    \n",
    "    if hour not  in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "\n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.703648312Z",
     "start_time": "2024-04-24T00:17:14.677851314Z"
    }
   },
   "id": "b39d080bcefffdc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8503ea23d784c72e"
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.58], ['13', 14.74], ['10', 13.44], ['14', 13.23], ['16', 16.8], ['23', 7.99], ['12', 9.41], ['17', 11.46], ['15', 38.59], ['21', 16.01], ['20', 21.52], ['02', 23.81], ['18', 13.2], ['03', 7.8], ['05', 10.09], ['19', 10.8], ['01', 11.38], ['22', 6.75], ['08', 10.25], ['04', 7.17], ['00', 8.13], ['06', 9.02], ['07', 7.85], ['11', 11.05]]\n"
     ]
    }
   ],
   "source": [
    "avg_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    average_comments = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_hour.append([hour,round(average_comments,2)])\n",
    "\n",
    "print(avg_hour)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.703719990Z",
     "start_time": "2024-04-24T00:17:14.677942713Z"
    }
   },
   "id": "f6f915c4fba3e339"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although we now have the results we need, this format makes it difficult to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "549ef7fa9a23d0b"
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.58, '09'], [14.74, '13'], [13.44, '10'], [13.23, '14'], [16.8, '16'], [7.99, '23'], [9.41, '12'], [11.46, '17'], [38.59, '15'], [16.01, '21'], [21.52, '20'], [23.81, '02'], [13.2, '18'], [7.8, '03'], [10.09, '05'], [10.8, '19'], [11.38, '01'], [6.75, '22'], [10.25, '08'], [7.17, '04'], [8.13, '00'], [9.02, '06'], [7.85, '07'], [11.05, '11']]\n",
      "Top 5 Hours for Ask Posts Comments:\n",
      "15:00 38.59 average comments per post\n",
      "02:00 23.81 average comments per post\n",
      "20:00 21.52 average comments per post\n",
      "16:00 16.80 average comments per post\n",
      "21:00 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_hour:\n",
    "    listData = [row[1],row[0]]\n",
    "    swap_avg_by_hour.append(listData)\n",
    "\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments:\")\n",
    "\n",
    "for data in sorted_swap[:5]:\n",
    "    avg_comments = data[0]\n",
    "    data_object = dt.datetime.strptime(data[1],'%H')\n",
    "    hour = dt.datetime.strftime(data_object,\"%H:00\")\n",
    "    output = \"{hour} {avg_comments:.2f} average comments per post\"\n",
    "    print(output.format(hour = hour,avg_comments = avg_comments))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:17:14.703779574Z",
     "start_time": "2024-04-24T00:17:14.677972667Z"
    }
   },
   "id": "c50bb7186d0763d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimal Hours for Posting to Receive Comments\n",
    "\n",
    "To determine the optimal hours for creating posts to maximize the chances of receiving comments, we analyzed the provided data on the average number of comments per post for each hour of the day. However, since the dataset doesn't specify the time zone, we converted the times to the time zone we live in for accurate analysis.\n",
    "\n",
    "Upon converting the times to our local time zone, we found that the top hours for posting to have a higher chance of receiving comments are as follows:\n",
    "\n",
    "1. **3:00 PM (15:00)**: This hour has the highest average comments per post, indicating that posts created around this time tend to receive more comments compared to other hours. It suggests that the audience is more active and engaged during this time, making it an optimal time for posting content.\n",
    "\n",
    "2. **2:00 AM (02:00)**: The second-highest average comments per post are observed at 2:00 AM. Although it's an unconventional time for posting, it suggests that there might be a subset of the audience who are active during late-night hours, possibly due to different time zones or nocturnal habits.\n",
    "\n",
    "3. **8:00 PM (20:00)**: This hour ranks third in terms of average comments per post. Posting during the evening hours can be advantageous as people are often winding down from their day and spending more time on social media platforms.\n",
    "\n",
    "4. **4:00 PM (16:00)**: Posting at 4:00 PM also shows a significant average number of comments per post, indicating that it's another peak engagement hour where the audience is likely to be active and responsive.\n",
    "\n",
    "5. **9:00 PM (21:00)**: Rounding out the top five hours is 9:00 PM, suggesting that posting content during this time may also yield a higher chance of receiving comments.\n",
    "\n",
    "These insights provide valuable guidance for content creators or community managers in scheduling their posts strategically to maximize engagement and interaction with their audience. By targeting these peak hours, they can increase the visibility and impact of their content, ultimately driving more meaningful conversations and connections with their audience.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76302f9167ede6b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
